{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aace87c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\729sh\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from reasoning_gym import get_score_answer_fn, create_dataset\n",
    "from prompts import *\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from rich import print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb7d908b",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 100\n",
    "batch_size = 2\n",
    "n_rollouts = 3\n",
    "buffer_size = 6\n",
    "max_new_tokens = 100\n",
    "model_name = \"HuggingFaceTB/SmolLM-135M-Instruct\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "091b7fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "env_name = \"propositional_logic\"\n",
    "dataset = create_dataset(env_name,seed=42, size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6ecb59d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4dd3c23c",
   "metadata": {},
   "outputs": [],
   "source": [
    "entry = dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eb433b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = entry[\"question\"]\n",
    "answer = entry['metadata']['example_answer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eff9df0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_object = entry[\"metadata\"][\"source_dataset\"]\n",
    "score_fn = get_score_answer_fn(validation_object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eac18986",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": system_prompt},\n",
    "    {\"role\": \"user\", \"content\": question}, # Obtained from reasoning-gym\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7303b92a",
   "metadata": {},
   "outputs": [],
   "source": [
    "templated_string = tokenizer.apply_chat_template(\n",
    "        messages,\n",
    "        tokenize=False,\n",
    "        # return_tensors=\"pt\",\n",
    "        add_generation_prompt=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c9c410db",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer(\n",
    "        [templated_string],\n",
    "        return_tensors=\"pt\",\n",
    "        padding_side=\"left\",\n",
    "        max_length=512,\n",
    "        padding='max_length',\n",
    "        # # truncation=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "831dc56d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">torch.Size</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">512</span><span style=\"font-weight: bold\">])</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m512\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(inputs[\"input_ids\"].shape)  # torch.Size([1, 75])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "71b4a53f",
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_response = model.generate(\n",
    "        input_ids=inputs['input_ids'],\n",
    "        attention_mask=inputs[\"attention_mask\"],\n",
    "        max_new_tokens=max_new_tokens, # The max number of tokens to generate\n",
    "        do_sample=True,                # Probabilistic sampling\n",
    "        top_p=0.95,                    # Nucleus sampling\n",
    "        num_return_sequences=n_rollouts,        # Number of sequences per question\n",
    "        temperature=1,                 # Increase randomness\n",
    "        eos_token_id=tokenizer.eos_token_id,\n",
    "        pad_token_id=tokenizer.eos_token_id,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0e6cfff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "decoded_resp = tokenizer.batch_decode(generated_response[:, inputs[\"input_ids\"].shape[1]:]) # Remove the prompt part\n",
    "extract_answers = [extract_answer(decoded_resp[i]) for i in range(n_rollouts)]\n",
    "rewards = calculate_total_reward(decoded_resp, np.repeat(entry, n_rollouts))\n",
    "# extract_answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ef42230d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0.]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rewards = np.reshape(rewards, (1, n_rollouts))\n",
    "advantages = (rewards - np.mean(rewards, axis=1, keepdims=True)) / (\n",
    "    np.std(rewards, axis=1, keepdims=True) + 1e-8\n",
    ")\n",
    "# advantages = advantages.reshape(-1, 1)\n",
    "advantages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bbe44669",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 512])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs[\"attention_mask\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5ef040bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_probs = calculate_logits(model, generated_response, inputs[\"attention_mask\"].repeat(n_rollouts, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c46c6769",
   "metadata": {},
   "outputs": [],
   "source": [
    "padded_tokens = (generated_response!=tokenizer.eos_token_id).int()\n",
    "response_start_idx = padded_tokens.argmax(axis=-1)\n",
    "response_end_idx = padded_tokens.shape[1] - torch.flip(padded_tokens, dims=[1]).argmax(dim=1)\n",
    "response_mask = torch.zeros_like(padded_tokens)\n",
    "for i in range(response_mask.shape[0]):\n",
    "    response_mask[i, inputs['input_ids'].shape[-1]:response_end_idx[i]] = 1\n",
    "    experience = [\n",
    "        {'input_sequence': generated_response[\n",
    "                i, response_start_idx[i]:response_end_idx[i]\n",
    "            ],\n",
    "         'response_mask': response_mask[\n",
    "                i, response_start_idx[i]:response_end_idx[i]\n",
    "            ],\n",
    "         'log_probs': log_probs[\n",
    "                i, response_start_idx[i]:response_end_idx[i]\n",
    "            ],\n",
    "         'advantage': advantages[i]\n",
    "        }\n",
    "        for i in range(1)\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f2b5b4dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span><span style=\"font-weight: bold\">)</span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">torch.Size</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">612</span><span style=\"font-weight: bold\">])</span>\n",
       "<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span><span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m3\u001b[0m\u001b[1m)\u001b[0m\n",
       "\u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m3\u001b[0m, \u001b[1;36m612\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n",
       "\u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m3\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(advantages.shape, log_probs.shape, rewards.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b7c3eb31",
   "metadata": {},
   "outputs": [],
   "source": [
    "advantages = torch.tensor(advantages, dtype = torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "575725df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 612])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(advantages@log_probs).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a350efea",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_log_probs = calculate_logits(model, generated_response, inputs[\"attention_mask\"].repeat(n_rollouts, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f310d70a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_policy_loss(new_log_probs, old_log_probs, advantages, response_mask):\n",
    "    ratioes = new_log_probs/old_log_probs\n",
    "    relavant_ratioes = ratioes*response_mask\n",
    "    clipped_term = advantages@torch.clip(relavant_ratioes, 0.8, 1.2)\n",
    "    unclipped_term = advantages@relavant_ratioes\n",
    "    grpo_term = torch.min(unclipped_term, clipped_term)\n",
    "    loss = torch.sum(grpo_term)/grpo_term.shape[1]\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1054138d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0,  ..., 1, 1, 1],\n",
       "        [0, 0, 0,  ..., 1, 1, 1],\n",
       "        [0, 0, 0,  ..., 1, 1, 1]], dtype=torch.int32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bc659d2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0., grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "compute_policy_loss(new_log_probs, log_probs, advantages, response_mask)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
